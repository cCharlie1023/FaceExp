(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{357:function(t,_,a){"use strict";a.r(_);var s=a(4),l=Object(s.a)({},(function(){var t=this,_=t._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h2",{attrs:{id:"_2024-4-1"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2024-4-1"}},[t._v("#")]),t._v(" 2024-4-1")]),t._v(" "),_("ol",[_("li",[t._v("项目拷打")]),t._v(" "),_("li",[t._v("学习途径")]),t._v(" "),_("li",[t._v("JVM调参")]),t._v(" "),_("li",[t._v("GC相关")]),t._v(" "),_("li",[t._v("手写单例（DCL、恶汉、懒汉、静态内部类、枚举）")])]),t._v(" "),_("h2",{attrs:{id:"_2024-3-22"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2024-3-22"}},[t._v("#")]),t._v(" 2024-3-22")]),t._v(" "),_("ol",[_("li",[t._v("给定一个文本文件，计算得到文本文件中出现频次最高的十个单词（手写，考虑内存消耗，文本文件会很大）")]),t._v(" "),_("li",[t._v("如果是1000个文本文件，找出这1000个文本文件中出现频次最高的十个单词。\n关键在于去重。因为无法预知不同文本中含有相同单词的情况，所以可以首先对单个文件进行统计，key为单词，value为次数。然后比如使用二十个文件来统计单词情况，将每个文本统计的key做hash，再mod20，分布在不同文件中，这样保证了不同文本中的单词不存在相同情况，再对单个文本词频进行统计。以此类推，进行去重\n接着开始对词频取top10，可以使用诸如分治等，使用大顶堆这样的数据结构来做。")])])])}),[],!1,null,null,null);_.default=l.exports}}]);